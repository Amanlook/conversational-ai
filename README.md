# Dual-Mode AI Assistant

A professional, high-performance dual-mode AI assistant built with **PydanticAI** and **async/await** architecture for concurrent request processing and optimal performance.

![Python](https://img.shields.io/badge/python-3.14+-blue.svg)
![PydanticAI](https://img.shields.io/badge/PydanticAI-1.7.0+-green.svg)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-orange.svg)
![Async](https://img.shields.io/badge/async-enabled-purple.svg)

## ğŸ¯ Features

### Dual Operating Modes
- **ğŸ—£ï¸ Conversational Mode** - Context-aware friendly chat with conversation history
- **âœï¸ Rephrasing Mode** - Professional grammar correction and text improvement

### High-Performance Architecture
- **âš¡ Async/Await** - Non-blocking operations for better performance
- **ğŸš€ Concurrent Processing** - Handle multiple requests simultaneously
- **ğŸ”„ Backward Compatible** - Sync versions of all methods available
- **ğŸ“¦ Modular Design** - Clean separation of concerns with SOLID principles

### Professional Features
- **ğŸ¨ Clean Class-Based Architecture** - Maintainable and extensible code
- **ğŸ›¡ï¸ Type Safety** - Full type hints and validation
- **âš ï¸ Error Handling** - Graceful failure recovery and user feedback
- **ğŸ“Š Usage Analytics** - Conversation statistics and metrics
- **ğŸ§ª Comprehensive Testing** - Demo script with various scenarios

## ğŸš€ Quick Start

### Prerequisites
- Python 3.14+
- OpenAI API key

### Installation

1. **Clone the repository:**
```bash
git clone <repository-url>
cd pydantic_ai
```

2. **Install dependencies:**
```bash
pip install -e .
# or with uv
uv sync
```

3. **Set up environment:**
```bash
cp .env.example .env
# Add your OpenAI API key to .env file
echo "OPENAI_API_KEY=your_api_key_here" > .env
```

### Usage

#### Interactive Mode
```bash
python main.py
```

Then use the dual-mode format:
```
You: conversational: How does machine learning work?
ğŸ¤– Machine learning is a fascinating field where...

You: rephrasing: I went to store yesterday and buy some food
âœï¸  I went to the store yesterday and bought some food.
```

#### Programmatic Usage
```python
import asyncio
from src.core.assistant import DualModeAssistant

async def main():
    assistant = DualModeAssistant()

    # Single request
    result = await assistant.process_single_request(
        "conversational: Explain neural networks"
    )
    print(result["response"])

    # Interactive session
    await assistant.start_interactive_session()

asyncio.run(main())
```

#### Concurrent Processing
```python
async def batch_process():
    assistant = DualModeAssistant()

    requests = [
        "conversational: What is Python?",
        "rephrasing: me and my friend goes to school",
        "conversational: How does async work?",
        "rephrasing: this code work good"
    ]

    # Process all requests concurrently (3-4x faster!)
    tasks = [assistant.process_single_request(req) for req in requests]
    results = await asyncio.gather(*tasks)

    for result in results:
        print(f"âœ… {result['response']}")
```

#### Demo Mode
```bash
python demo_dual_mode.py
```

## ğŸ—ï¸ Architecture

### Project Structure
```
pydantic_ai/
â”œâ”€â”€ main.py                     # Async entry point
â”œâ”€â”€ demo_dual_mode.py          # Comprehensive demo with concurrent examples
â”œâ”€â”€ .env                       # API configuration
â”œâ”€â”€ pyproject.toml            # Project dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                 # Main business logic
â”‚   â”‚   â”œâ”€â”€ assistant.py      # DualModeAssistant orchestrator
â”‚   â”‚   â””â”€â”€ conversation_manager.py # Chat history & context
â”‚   â”œâ”€â”€ ai/                   # AI agent management
â”‚   â”‚   â””â”€â”€ agent_manager.py  # PydanticAI agent wrapper
â”‚   â”œâ”€â”€ helpers/              # Utility classes
â”‚   â”‚   â”œâ”€â”€ input_parser.py   # Mode detection & validation
â”‚   â”‚   â””â”€â”€ ui_helper.py      # User interface utilities
â”‚   â””â”€â”€ scripts/              # Legacy/backup files
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ README_ASYNC.md          # Detailed async documentation
â””â”€â”€ README_REFACTORED.md     # Architecture details
```

### Component Overview

#### ğŸ›ï¸ **DualModeAssistant** (Main Orchestrator)
- Coordinates all components
- Manages interactive sessions
- Handles async/sync compatibility
- Provides API-like interface

#### ğŸ¤– **AgentManager** (AI Interface)
- Manages PydanticAI agents
- Handles model configuration
- Provides async and sync methods
- Supports multiple AI models

#### ğŸ’¬ **ConversationManager** (Context Handling)
- Maintains conversation history
- Manages context windows
- Provides conversation analytics
- Optimizes memory usage

#### ğŸ” **InputParser** (Request Processing)
- Validates user input
- Detects operating modes
- Handles edge cases
- Provides structured responses

#### ğŸ¨ **UIHelper** (User Interface)
- Consistent message formatting
- Async/sync input handling
- Progress indicators
- Error display utilities

## ğŸ® Usage Examples

### Mode Examples

#### Conversational Mode
```
Input:  conversational: What are the benefits of learning Python?
Output: Python offers numerous benefits including:
        - Easy-to-read syntax that's beginner-friendly
        - Vast ecosystem with libraries for data science, web dev, AI
        - Strong community support and extensive documentation
        - Cross-platform compatibility
        - High demand in job market...
```

#### Rephrasing Mode
```
Input:  rephrasing: The meeting was very productive and we discuss many topics
Output: The meeting was very productive and we discussed many topics.

Input:  rephrasing: This code need to be optimize for better performance
Output: This code needs to be optimized for better performance.
```

### API-Style Usage
```python
# Process single request
result = await assistant.process_single_request("conversational: Hello!")

# Response structure
{
    "success": True,
    "response": "Hello! How can I help you today?",
    "mode": "conversational",
    "original_input": "Hello!"
}

# Error handling
{
    "success": False,
    "error": "Please provide content after the mode label.",
    "mode": "conversational"
}
```

## âš¡ Performance Features

### Async Benefits
- **Concurrent AI Calls**: Process multiple requests simultaneously
- **Non-blocking I/O**: User input doesn't freeze the application
- **Better Resource Usage**: More efficient CPU and memory utilization
- **Scalability**: Handle hundreds of concurrent requests

### Performance Comparison
```python
# Sequential Processing (Old)
for request in requests:
    result = agent.run_sync(request)  # ~2-3 seconds each
# Total: 8-12 seconds for 4 requests

# Concurrent Processing (New)
tasks = [agent.run(req) for req in requests]
results = await asyncio.gather(*tasks)  # ~2-3 seconds total
# Total: 2-3 seconds for 4 requests (75% faster!)
```

## ğŸ› ï¸ Configuration

### Model Selection
```python
# Use different OpenAI models
assistant = DualModeAssistant(model_name="openai:gpt-4o")
assistant = DualModeAssistant(model_name="openai:gpt-4o-mini")
```

### Conversation History
```python
from src.core.conversation_manager import ConversationManager

# Adjust history length
conversation_manager = ConversationManager(max_history_pairs=5)
```

### Environment Variables
```bash
# .env file
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Model configuration
DEFAULT_MODEL=openai:gpt-4o
MAX_HISTORY_PAIRS=3
```

## ğŸ§ª Testing & Development

### Run Demo
```bash
python demo_dual_mode.py
```

### Development Setup
```bash
# Install dev dependencies
uv sync --group dev

# Run linting
ruff check .
ruff format .

# Pre-commit hooks
pre-commit install
pre-commit run --all-files
```

### Adding New Features

#### New Operating Mode
1. Extend `Mode` enum in `input_parser.py`
2. Add agent creation in `agent_manager.py`
3. Update parsing logic in `InputParser`
4. Add handling in `DualModeAssistant`

#### Custom Agent
```python
class CustomAgentManager(AgentManager):
    async def get_translation_response(self, text: str, target_lang: str) -> str:
        agent = self._create_translation_agent(target_lang)
        result = await agent.run(text)
        return str(result)
```

## ğŸ“Š Monitoring & Analytics

### Conversation Statistics
```python
# Get conversation metrics
stats = assistant.get_conversation_stats()
print(stats)  # {"message_count": 6, "has_context": True}

# Clear conversation history
assistant.clear_conversation_history()
```

### Error Tracking
```python
try:
    result = await assistant.process_single_request("conversational: Hello!")
    if not result["success"]:
        logger.error(f"Request failed: {result['error']}")
except Exception as e:
    logger.exception(f"Unexpected error: {e}")
```

## ğŸš€ Advanced Usage

### Rate Limiting
```python
import asyncio
from asyncio import Semaphore

async def rate_limited_process(requests, max_concurrent=3):
    semaphore = Semaphore(max_concurrent)

    async def limited_request(request):
        async with semaphore:
            return await assistant.process_single_request(request)

    tasks = [limited_request(req) for req in requests]
    return await asyncio.gather(*tasks)
```

### Timeout Handling
```python
async def process_with_timeout(request, timeout=30):
    try:
        result = await asyncio.wait_for(
            assistant.process_single_request(request),
            timeout=timeout
        )
        return result
    except asyncio.TimeoutError:
        return {"success": False, "error": "Request timed out"}
```

### Batch Processing
```python
async def batch_process(requests, batch_size=5):
    for i in range(0, len(requests), batch_size):
        batch = requests[i:i + batch_size]
        tasks = [assistant.process_single_request(req) for req in batch]
        results = await asyncio.gather(*tasks)

        for result in results:
            if result["success"]:
                yield result["response"]
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes following the existing architecture
4. Add tests for new functionality
5. Run linting: `ruff check . && ruff format .`
6. Commit changes: `git commit -m 'Add amazing feature'`
7. Push to branch: `git push origin feature/amazing-feature`
8. Open a Pull Request

### Code Style
- Follow PEP 8 guidelines
- Use type hints for all functions
- Write docstrings for classes and methods
- Maintain async/sync compatibility
- Add error handling for all operations

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **PydanticAI** - For the excellent AI agent framework
- **OpenAI** - For providing powerful language models
- **Python asyncio** - For enabling high-performance concurrent operations

---

## ğŸ“š Documentation

- **[README_ASYNC.md](README_ASYNC.md)** - Detailed async architecture documentation
- **[README_REFACTORED.md](README_REFACTORED.md)** - Class-based architecture details
- **[Demo Script](demo_dual_mode.py)** - Comprehensive usage examples

## ğŸ†˜ Troubleshooting

### Common Issues

**API Key Error**
```bash
âŒ Failed to start assistant: No OpenAI API key found
```
**Solution**: Add your API key to `.env` file

**Import Error**
```bash
ModuleNotFoundError: No module named 'src'
```
**Solution**: Run from project root or install with `pip install -e .`

**Async Runtime Error**
```bash
RuntimeError: asyncio.run() cannot be called from a running event loop
```
**Solution**: Use `await` in async contexts, not `asyncio.run()`

---

*Built with â¤ï¸ using PydanticAI, Python asyncio, and modern software architecture principles*
